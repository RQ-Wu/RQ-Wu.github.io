<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="author" content="Ruiqi Wu">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rui-Qi Wu - Academic Portfolio</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <style>
        /* 主色板：基于深色和中性色，突出专业感 */
        :root {
            --color-background: #ffffff; 
            --color-surface: #f7f7f7;    
            --color-text-primary: #1e1e1e; 
            --color-text-secondary: #5f6368; 
            --color-accent: #004d99; /* 深海军蓝/普鲁士蓝作为强调色 */
            --color-highlight: #b30000; /* 红色用于重要/新闻高亮 */
            
            /* 几何与效果 */
            --radius-default: 6px;
            --shadow-subtle: 0 1px 3px rgba(0, 0, 0, 0.06);
            --shadow-hover: 0 4px 10px rgba(0, 0, 0, 0.1);
            --transition-duration: 0.2s;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
        }

        body {
            background-color: var(--color-surface);
            color: var(--color-text-primary);
            line-height: 1.6;
            padding: 40px 0;
        }

        /* 容器样式：纯净、无阴影 */
        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: var(--color-background);
            border-radius: var(--radius-default);
            box-shadow: 0 0 0 1px rgba(0, 0, 0, 0.05);
            overflow: hidden;
        }
        
        a {
            color: var(--color-accent);
            text-decoration: none;
            transition: color var(--transition-duration);
        }

        a:hover {
            color: #0077c2;
            text-decoration: underline;
        }

        /* --- 头部区域 (Header) --- */
        header {
            display: flex;
            flex-wrap: wrap;
            align-items: center;
            padding: 40px;
            border-bottom: 1px solid var(--color-surface);
        }

        .profile-info {
            flex: 1;
            min-width: 300px;
            padding-right: 30px;
        }

        .profile-name {
            font-size: 28px;
            font-weight: 700;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            color: var(--color-text-primary);
        }

        .profile-name i {
            margin-right: 12px;
            color: var(--color-accent);
            font-size: 32px;
        }

        .social-links {
            margin-bottom: 20px;
        }

        .social-links a {
            font-size: 14px;
            margin-right: 15px;
            color: var(--color-text-secondary);
            display: inline-block;
            padding: 3px 0;
        }
        
        .social-links a:hover {
            color: var(--color-accent);
            text-decoration: none;
        }

        .social-links i {
            margin-right: 5px;
        }

        .profile-bio {
            font-size: 15px;
            color: var(--color-text-primary);
            line-height: 1.8;
        }

        .profile-photo {
            flex: 0 0 140px; 
            width: 140px;
            height: 140px;
            border-radius: 50%;
            overflow: hidden;
            margin-left: auto;
            border: 4px solid var(--color-background);
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .profile-photo img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        /* --- 章节通用样式 --- */
        section {
            padding: 40px;
        }

        .section-title {
            font-size: 24px;
            font-weight: 600;
            margin-bottom: 30px;
            padding-bottom: 10px;
            border-bottom: 2px solid var(--color-accent); 
            display: flex;
            align-items: center;
            color: var(--color-accent);
        }

        .section-title i {
            font-size: 30px;
            margin-right: 15px;
        }
        
        /* --- 实习经历 (Experience) 样式 --- */
        #experience {
            border-bottom: 1px solid rgba(0, 0, 0, 0.05); 
        }

        .experience-list {
            display: flex;
            flex-wrap: wrap;
            gap: 30px; 
            list-style: none;
            padding: 0;
            justify-content: space-around; /* 居中对齐 */
        }

        .experience-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
            width: 150px; /* 略微增大宽度 */
            transition: transform 0.2s, box-shadow 0.2s;
            padding: 10px 0;
        }

        .experience-item:hover {
            transform: translateY(-3px); 
        }

        .exp-logo {
            width: 70px; 
            height: 70px;
            border-radius: 50%;
            overflow: hidden;
            margin-bottom: 15px;
            background-color: var(--color-background);
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(0, 0, 0, 0.05);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .exp-logo img {
            width: 90%; 
            height: 90%;
            object-fit: contain; 
            border-radius: 50%;
        }

        .exp-company {
            font-size: 16px;
            font-weight: 600;
            color: var(--color-text-primary);
            margin-bottom: 4px;
        }

        .exp-title {
            font-size: 14px;
            color: var(--color-text-secondary);
            margin-bottom: 2px;
        }

        .exp-period {
            font-size: 12px;
            color: var(--color-text-secondary);
        }

        /* --- 新闻列表 (Recent News) --- */
        .news-list {
            list-style: none; 
            padding-left: 30px;
        }

        .news-list li {
            margin-bottom: 10px;
            font-size: 15px;
            padding-left: 1.2em;
            text-indent: -1.2em;
        }
        
        .news-list li::before {
            content: "\2022"; 
            color: var(--color-accent);
            font-weight: bold;
            display: inline-block; 
            width: 1.2em;
        }

        .news-date {
            color: var(--color-text-secondary);
            font-weight: 400;
            margin-right: 8px;
        }

        .news-highlight {
            color: var(--color-highlight); 
            font-weight: 600;
        }

        /* --- 出版物 (Publications) --- */
        .publication-note {
            font-size: 14px;
            margin-bottom: 20px;
            color: var(--color-text-secondary);
        }

        .pub-category {
            margin: 35px 0 15px 0;
            font-size: 20px;
            font-weight: 600;
            color: var(--color-text-primary);
            padding-bottom: 5px;
        }

        .publication {
            display: flex;
            flex-wrap: wrap;
            margin-bottom: 25px;
            padding: 20px;
            background-color: var(--color-surface); 
            border-radius: var(--radius-default);
            transition: box-shadow var(--transition-duration);
        }

        .publication:hover {
            box-shadow: var(--shadow-hover);
            background-color: #f0f0f0; 
        }

        .pub-image {
          flex: 0 0 200px;
          height: 120px;
          margin-right: 25px;
          position: relative;
          border-radius: var(--radius-default);
          overflow: hidden;
          box-shadow: var(--shadow-subtle);
          transition: none;
        }

        .pub-image img {
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: block;
        }
        
        .pub-image .hover-image {
            position: absolute;
            top: 0;
            left: 0;
            opacity: 0;
            transition: opacity var(--transition-duration);
        }

        .pub-image:hover .hover-image {
            opacity: 1;
        }

        .pub-content {
            flex: 1;
            min-width: 350px;
        }

        .pub-title {
            font-size: 17px;
            font-weight: 600;
            margin-bottom: 5px;
            line-height: 1.4;
        }

        .pub-authors {
            font-size: 14px;
            margin-bottom: 5px;
            color: var(--color-text-secondary);
        }
        
        .pub-authors strong {
            color: var(--color-text-primary); 
            font-weight: 600;
        }

        .pub-venue {
            font-size: 14px;
            margin-bottom: 12px;
            color: var(--color-text-secondary);
        }
        
        .pub-highlight {
            color: var(--color-highlight); 
            font-weight: 600;
            margin-left: 5px;
        }

        .pub-badges img {
            position: relative;
            top: 3px;
            height: 16px; 
            margin-left: 8px;
            filter: grayscale(10%); 
        }

        .pub-links {
            margin-top: 10px;
        }

        .pub-links a {
            font-size: 14px;
            margin-right: 18px;
            white-space: nowrap;
            color: var(--color-accent);
        }

        .pub-links i {
            margin-right: 5px;
        }

        /* --- 荣誉奖项 (Honors & Awards) --- */
        .awards-list {
            list-style: none; 
            padding-left: 0;
        }

        .awards-list li {
            margin-bottom: 10px;
            font-size: 15px;
            padding-left: 1.2em; 
            text-indent: -1.2em;
        }
        
        .awards-list li::before {
            content: "\2022"; 
            color: var(--color-accent);
            font-weight: bold;
            display: inline-block; 
            width: 1.2em;
        }

        /* --- 页脚 (Footer) --- */
        footer {
            text-align: center;
            padding: 25px;
            border-top: 1px solid rgba(0, 0, 0, 0.05);
            font-size: 12px;
            color: var(--color-text-secondary);
            margin-top: 20px;
        }

        .clustrmaps-widget {
            display: inline-block;
            margin-bottom: 10px;
        }
        
        /* 隐藏超出默认数量的列表项 */
        .news-list li.hidden-news {
            display: none;
        }
        
        .news-list li::before, .awards-list li::before {
            content: "\2022"; 
            color: var(--color-accent);
            font-weight: bold;
            display: inline-block; 
            width: 0.2em; /* 控制点本身占据的空间宽度 */
        }

        /* 按钮基础样式 */
        .toggle-btn {
            display: block;
            width: 100%;
            padding: 10px 15px;
            margin-top: 15px;
            background-color: transparent;
            border: 1px solid var(--color-accent);
            color: var(--color-accent);
            font-size: 14px;
            font-weight: 500;
            cursor: pointer;
            border-radius: var(--radius-default);
            transition: background-color var(--transition-duration), transform var(--transition-duration);
        }

        .toggle-btn:hover {
            background-color: var(--color-accent);
            color: var(--color-background);
        }

        .toggle-btn i {
            margin-right: 8px;
            transition: transform 0.3s ease;
        }

        /* 展开状态下的图标旋转 */
        .toggle-btn[aria-expanded="true"] i {
            transform: rotate(180deg);
        }

        /* 按钮加载完毕前的默认隐藏，防止闪烁 */
        #toggle-news-btn {
            visibility: hidden;
        }

        /* --- 响应式调整 --- */
        @media (max-width: 768px) {
            body { padding: 20px 0; }
            header {
                flex-direction: column;
                text-align: center;
                padding: 30px 20px;
            }
            .profile-photo { margin: 20px auto 0; }
            .profile-info { padding-right: 0; }
            .profile-name { justify-content: center; }
            .social-links { text-align: center; }
            .profile-bio { text-align: left; }
            section { padding: 20px; }
            .section-title { margin-bottom: 20px; font-size: 20px; }
            .publication { flex-direction: column; padding: 15px; }
            .pub-image {
                margin-right: 0;
                margin-bottom: 15px;
                width: 100%;
                max-width: 300px;
                margin-left: auto;
                margin-right: auto;
                height: 150px; 
            }
            .pub-content { min-width: unset; }
            
            /* 移动端实习经历布局 */
            .experience-list {
                flex-wrap: nowrap;
                overflow-x: auto; 
                padding-bottom: 10px;
                justify-content: flex-start;
            }
            .experience-item {
                flex-shrink: 0; 
                width: 120px;
            }
        }
    </style>
    
    <script id="experience-data" type="application/json">
    {
      "experiences": [
        {
          "company": "Megvii",
          "period": "2023.06 - 2023.10",
          "title": "Research Intern",
          "logoUrl": "https://cdnstatic.megvii.com/websiteFE/static/img/logo_new_hover.2a536506.png"
        },
        {
          "company": "StepFun",
          "period": "2023.10 - 2024.02",
          "title": "Research Intern",
          "logoUrl": "https://avatars.githubusercontent.com/u/178004800?s=280&v=4"
        },
        {
          "company": "Horizon Robotics",
          "period": "2024.02 - 2025.08",
          "title": "Research Intern",
          "logoUrl": "https://avatars.githubusercontent.com/u/46703330?s=200&v=4"
        },
        {
          "company": "Meituan",
          "period": "2025.08 - Now",
          "title": "Beidou Intern",
          "logoUrl": "https://play-lh.googleusercontent.com/C4OV39W_PKA0goub32o1ZwjSsKekUDPm-BQiAXDKn-WPk03cDrXRRsuN5Q02L50bnOyl"
        }
      ]
    }
    </script>

    <script id="publication-data" type="application/json">
    {
      "categories": [
        {
          "title": "First author paper",
          "pubs": [
            {
              "id": "DIPO",
              "title": "DIPO: Dual-State Images Controlled Articulated Object Generation Powered by Diverse Data",
              "authors": ["**Ruiqi Wu**", "Xinjie Wang", "Liu Liu", "Chunle Guo", "Jiaxiong Qiu", "Chongyi Li", "Lichao Huang", "Zhizhong Su", "Ming-Ming Cheng"],
              "venue": "NeurIPS 2025",
              "badge_stars": "https://img.shields.io/github/stars/RQ-Wu/DIPO?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/RQ-Wu/DIPO?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "https://github.com/RQ-Wu/DIPO/raw/master/assets/method.png",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/pdf/2505.20460", "icon": "fa-file-pdf"},
                {"text": "中文版", "url": "https://rq-wu.github.io/projects/DIPO/DIPO_CN.pdf", "icon": "fa-language"},
                {"text": "Project", "url": "https://rq-wu.github.io/projects/DIPO/index.html", "icon": "fa-globe"},
                {"text": "Code", "url": "https://github.com/RQ-Wu/DIPO", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/DIPO.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "LAMP",
              "title": "LAMP: Learn A Motion Pattern for Few-Shot Video Generation",
              "authors": ["**Rui-Qi Wu**", "Liang-Yu Chen", "Tong Yang", "Chun-Le Guo", "Chong-Yi Li", "Xiang-Yu Zhang"],
              "venue": "CVPR 2024",
              "badge_stars": "https://img.shields.io/github/stars/RQ-Wu/LAMP?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/RQ-Wu/LAMP?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "images/LAMP/LOGO.png",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/abs/2310.10769", "icon": "fa-file-pdf"},
                {"text": "Project", "url": "https://rq-wu.github.io/projects/LAMP/index.html", "icon": "fa-globe"},
                {"text": "Code", "url": "https://github.com/RQ-Wu/LAMP", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/LAMP.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "RIDCP",
              "title": "RIDCP: Revitalizing Real Image Dehazing via High-Quality Codebook Priors",
              "authors": ["**Rui-Qi Wu**", "Zheng-Peng Duan", "Chun-Le Guo", "Zhi Chai", "Chong-Yi Li"],
              "venue": "CVPR 2023",
              "badge_stars": "https://img.shields.io/github/stars/RQ-Wu/RIDCP_dehazing?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/RQ-Wu/RIDCP_dehazing?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "images/RIDCP/dehaze.gif",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/abs/2304.03994", "icon": "fa-file-pdf"},
                {"text": "中文版", "url": "#", "icon": "fa-language"},
                {"text": "Project", "url": "projects/RIDCP/index.html", "icon": "fa-globe"},
                {"text": "Code", "url": "https://github.com/RQ-Wu/RIDCP", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/RIDCP.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "URanker",
              "title": "Underwater Ranker: Learn Which Is Better and How to Be Better",
              "authors": ["Chun-Le Guo*", "**Rui-Qi Wu***","Xin Jin", "Ling-Hao Han", "Zhi Chai", "Wei-Dong Zhang", "Chong-Yi Li"],
              "venue": "AAAI 2023 <span class='pub-highlight'>(Oral Presentation)</span>",
              "badge_stars": "https://img.shields.io/github/stars/RQ-Wu/UnderwaterRanker?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/RQ-Wu/UnderwaterRanker?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "images/URanker/main.png",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/abs/2208.06857", "icon": "fa-file-pdf"},
                {"text": "中文版", "url": "#", "icon": "fa-language"},
                {"text": "Project", "url": "https://li-chongyi.github.io/URanker_files/", "icon": "fa-globe"},
                {"text": "Code", "url": "https://github.com/RQ-Wu/UnderwaterRanker", "icon": "fa-code"},
                {"text": "Dataset", "url": "https://pan.baidu.com/s/1K29p3gJWYa1ZM0vMHqI4uA", "icon": "fa-database"}
              ]
            },
            {
              "id": "ICME2021",
              "title": "Stereo Superpixel Segmentation Via Dual-Attention Fusion Networks",
              "authors": ["**Rui-Qi Wu**", "Ya-Juan Du", "Hua Li", "Yu-Cong Dai"],
              "venue": "ICME 2021 <span class='pub-highlight'>(Oral Presentation)</span>",
              "imageUrl": "images/StereoSuperpixel/ICME.png",
              "links": [
                {"text": "PDF", "url": "https://ieeexplore.ieee.org/abstract/document/9428302", "icon": "fa-file-pdf"},
                {"text": "BibTex", "url": "bibs/ICME.html", "icon": "fa-book-open"}
              ]
            }
          ]
        },
        {
          "title": "Other publications",
          "pubs": [
            {
              "id": "embodied-gen",
              "title": "EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence",
              "authors": ["Xinjie Wang", "Liu Liu", "Yu Cao", "**Ruiqi Wu**", "Wenkang Qin", "Dehui Wang", "Wei Sui", "Zhizhong Su"],
              "venue": "Technique Report",
              "badge_stars": "https://img.shields.io/github/stars/HorizonRobotics/EmbodiedGen?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/HorizonRobotics/EmbodiedGen?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "https://github.com/HorizonRobotics/EmbodiedGen/raw/master/docs/assets/overall.jpg",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/pdf/2506.10600", "icon": "fa-file-pdf"},
                {"text": "Project", "url": "https://horizonrobotics.github.io/robot_lab/embodied_gen/index.html", "icon": "fa-globe"},
                {"text": "Code", "url": "https://github.com/HorizonRobotics/EmbodiedGen", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/IPC.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "IPC",
              "title": "Iterative Predictor-Critic Code Decoding for Real-World Image Dehazing",
              "authors": ["Jiayi Fu", "Siyu Liu", "Zikun Liu", "Chun-Le Guo", "Hyunhee Park", "**Ruiqi Wu**", "Guoqing Wang", "Chongyi Li"],
              "venue": "CVPR 2025",
              "badge_stars": "https://img.shields.io/github/stars/Jiayi-Fu/IPC-Dehaze?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/Jiayi-Fu/IPC-Dehaze?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "https://github.com/Jiayi-Fu/IPC-Dehaze/raw/main/.assets/overview.png",
              "links": [
                {"text": "PDF", "url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Iterative_Predictor-Critic_Code_Decoding_for_Real-World_Image_Dehazing_CVPR_2025_paper.pdf", "icon": "fa-file-pdf"},
                {"text": "Project", "url": "https://jiayi-fu.github.io/IPC-Dehaze_Homepage/", "icon": "fa-globe"},
                {"text": "Code", "url": "https://github.com/Jiayi-Fu/IPC-Dehaze", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/IPC.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "RAM",
              "title": "Restore Anything with Masks: Leveraging Mask Image Modeling for Blind All-in-One Image Restoration",
              "authors": ["Chu-Jie Qin", "**Rui-Qi Wu**", "Zi-Kun Liu", "Xin Lin", "Chun-Le Guo", "Hyun Hee Park", "Chong-Yi Li"],
              "venue": "ECCV 2024",
              "badge_stars": "https://img.shields.io/github/stars/Dragonisss/RAM?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/Dragonisss/RAM?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "images/RAM/2_pipeline-1.png",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/abs/2409.19403v1", "icon": "fa-file-pdf"},
                {"text": "Project", "url": "https://rq-wu.github.io/projects/RAM/index.html", "icon": "fa-globe"},
                {"text": "Code", "url": "https://github.com/Dragonisss/RAM", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/RAM.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "YOLO-MS",
              "title": "YOLO-MS: Rethinking Multi-Scale Representation Learning for Real-time Object Detection",
              "authors": ["Yu-Ming Chen", "Xin-Bin Yuan", "**Rui-Qi Wu**", "Jia-Bao Wang", "Qi-Bin Hou", "Ming-Ming Cheng"],
              "venue": "Arxiv Pre-print, 2023",
              "badge_stars": "https://img.shields.io/github/stars/FishAndWasabi/YOLO-MS?label=%F0%9F%8C%9F%20Star&color=blue",
              "badge_forks": "https://img.shields.io/github/forks/FishAndWasabi/YOLO-MS?label=%F0%9F%94%A7%20Fork&color=green",
              "imageUrl": "images/YOLO-MS/YOLO-MS.png",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/abs/2308.05480", "icon": "fa-file-pdf"},
                {"text": "Code", "url": "https://github.com/FishAndWasabi/YOLO-MS", "icon": "fa-code"},
                {"text": "AIWalker", "url": "https://mp.weixin.qq.com/s/FfG9vNM_a2k_zflWfuimsw", "icon": "fa-microchip"},
                {"text": "BibTex", "url": "bibs/YOLO-MS.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "EORNet",
              "title": "Towards Extremely Overexposed Image Restoration",
              "authors": ["Zheng-Peng Duan", "Xin Jin", "**Rui-Qi Wu**", "Chun-Le Guo", "Li Liu", "Chong-Yi Li"],
              "venue": "Under Review",
              "imageUrl": "images/EORNet/before.jpg",
              "hoverImageUrl": "images/EORNet/ours.jpg",
              "links": [
                {"text": "PDF", "url": "#", "icon": "fa-file-pdf"},
                {"text": "Code", "url": "#", "icon": "fa-code"},
                {"text": "BibTex", "url": "#", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "TMM2023",
              "title": "Stereo Superpixel Segmentation Via Decoupled Dynamic Spatial-Embedding Fusion Network",
              "authors": ["Hua Li*", "Jian-Feng Liang*", "**Rui-Qi Wu**", "Run-Min Cong", "Jun-Hui Wu", "Sam Tak Wu Kwong"],
              "venue": "IEEE TMM, 2023 <span class='pub-highlight'>(Extension from ICME2021)</span>",
              "imageUrl": "images/StereoSuperpixel/extension.png",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/abs/2208.08145", "icon": "fa-file-pdf"},
                {"text": "Code", "url": "#", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/superpixel.html", "icon": "fa-book-open"}
              ]
            },
            {
              "id": "IH2021",
              "title": "Image Harmonization by Matching Regional References",
              "authors": ["Zi-Yue Zhu", "Zhao Zhang", "Zheng Lin", "**Rui-Qi Wu**", "Zhi Chai", "Chun-Le Guo"],
              "venue": "Arxiv Pre-print, 2021",
              "imageUrl": "images/harmonized/before.png",
              "hoverImageUrl": "images/harmonized/after.png",
              "links": [
                {"text": "PDF", "url": "https://arxiv.org/abs/2204.04715", "icon": "fa-file-pdf"},
                {"text": "Code", "url": "#", "icon": "fa-code"},
                {"text": "BibTex", "url": "bibs/harmonize.html", "icon": "fa-book-open"}
              ]
            }
          ]
        }
      ]
    }
    </script>
</head>
<body>
    <div class="container">
        <header>
            <div class="profile-info">
                <div class="profile-name">
                    <i class="fas fa-user-circle"></i>
                    Rui-Qi Wu (武睿祺)
                </div>
                <div class="social-links">
                    <a href="https://scholar.google.com/citations?user=orim0kUAAAAJ&hl=en" target="_blank">
                        <i class="fab fa-google"></i> Google Scholar
                    </a>
                    <a href="https://github.com/RQ-Wu" target="_blank">
                        <i class="fab fa-github"></i> Github
                    </a>
                    <a href="https://www.zhihu.com/people/hou-ban-lu-shui" target="_blank">
                        <i class="fab fa-zhihu"></i> Zhihu (知乎)
                    </a>
                </div>
                <p class="profile-bio">
                    Rui-Qi Wu (武睿祺) is currently a <strong>Ph.D. candidate</strong> at <a href="https://github.com/MCG-NKU" target="_blank">@MCG-NKU</a>, Nankai University. His primary research interests include <strong>AIGC (AI-Generated Content)</strong> and <strong>Embodied AI</strong>, with expertise in generative models and robust vision algorithms.
                    <br>
                    He is serving as a <strong>Beidou Research Intern</strong> at <a href="https://github.com/MeiGen-AI" target="_blank">@MeiGen-AI, Meituan</a>. Previously, he gained significant industry experience as an intern at <a href="https://github.com/HorizonRobotics" target="_blank">@HorizonRobotics</a>, <a href="https://github.com/megvii-research" target="_blank">@megvii-research</a>, and <a href="https://github.com/stepfun-ai" target="_blank">@StepFun</a>.
                </p>
            </div>
            <div class="profile-photo">
                <a href="images/my.jpg">
                    <img src="images/my.jpg" alt="profile photo">
                </a>
            </div>
        </header>

        <section id="experience">
            <h2 class="section-title">
                <i class="fas fa-briefcase"></i> Experience
            </h2>
            <div id="experience-list-container">
                <p>Loading experience...</p> 
            </div>
        </section>

        <section id="news">
            <h2 class="section-title">
                <i class="fas fa-sun"></i> Recent News
            </h2>
            <ul class="news-list" id="news-list">
                <li><span class="news-date">[09/2025]</span> One paper is accepted by NeurIPS 2025.</li>
                <li><span class="news-date">[08/2025]</span> I received the <span class="news-highlight">Meituan Talent Program Internship Offer</span> and started working as a <span class="news-highlight">Beidou Intern</span>.</li>   
                <li><span class="news-date">[02/2025]</span> One paper is accepted by CVPR 2025.</li>   
                <li><span class="news-date">[07/2024]</span> One paper is accepted by ECCV 2024.</li>   
                <li><span class="news-date">[02/2024]</span> One paper is accepted by CVPR 2024.</li>
                <li><span class="news-date">[11/2023]</span> I have served as a reviewer for CVPR 2024.</li>
                <li><span class="news-date">[09/2023]</span> I have served as a reviewer for <span class="news-highlight">IEEE TPAMI</span> (IF: 24.314) and IEEE TCSVT (IF: 5.859).</li>
                <li><span class="news-date">[07/2023]</span> I have served as a reviewer for AAAI 2024.</li>
                <li><span class="news-date">[03/2023]</span> One paper was accepted by IEEE TMM.</li>
                <li><span class="news-date">[02/2023]</span> One paper was accepted by CVPR 2023.</li>
                <li><span class="news-date">[01/2023]</span> Our paper was awarded <span class="news-highlight">Oral Presentation</span> qualification by AAAI 2023.</li>
                <li><span class="news-date">[12/2022]</span> I have served as a reviewer for Neurocomputing (IF: 5.719).</li>
                <li><span class="news-date">[11/2022]</span> One paper was accepted by AAAI 2023.</li>
                <li><span class="news-date">[04/2022]</span> Our team won the <span class="news-highlight">Third Place</span> in RAW Image Blind De-noising, Megcup 2022.</li>
                <li><span class="news-date">[04/2022]</span> Our team won the <span class="news-highlight">Second Runner-up</span> in Night Photography Rendering Challenge, CVPRW 2022.</li>
                <li><span class="news-date">[03/2021]</span> One paper is accepted by ICME 2021 as <span class="news-highlight">Oral Presentation</span>.</li>
            </ul>
            <button id="toggle-news-btn" class="toggle-btn" aria-expanded="false">
                <i class="fas fa-chevron-down"></i> expand more
            </button>
        </section>

        <section id="publications">
            <h2 class="section-title">
                <i class="fas fa-book"></i> Publications
            </h2>
            <p class="publication-note">( * denotes contribution equally )</p>
            
            <div id="publication-list-container">
                <p>Loading publications...</p> 
            </div>
        </section>

        <section id="awards">
            <h2 class="section-title">
                <i class="fas fa-award"></i> Honors & Awards
            </h2>
            <ul class="awards-list">
                <li>National Scholarship, 2023 (Top 0.2% student in China).</li>
                <li>Second Runner-up (Team Feedforward) in <a href="https://studio.brainpp.com/competition/5?tab=rank" target="_blank">RAW Image Blind De-noising</a>.</li>
                <li>Second Runner-up (Team Feedback) in <a href="https://nightimaging.org/final-leaderboard.html" target="_blank">Night Photography Rendering Challenge, CVPR Workshop 2022</a>.</li>
                <li>Kaggle Bronze Medal (256 / 3900, Top 7%), <a href="https://www.kaggle.com/competitions/cassava-leaf-disease-classification" target="_blank">Cassava Leaf Disease Classification</a>.</li>
            </ul>
        </section>

        <footer>
            <div class="clustrmaps-widget">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=JPElC7CKF9eOZ1uV60wlNxD7SYWTT5UOyqvS06CiH3A"></script>
            </div>
            <p>&copy; Rui-Qi Wu | Last updated: Dec. 2025</p>
        </footer>
    </div>

    <script>
        const pubDataElement = document.getElementById('publication-data');
        const pubContainer = document.getElementById('publication-list-container');
        
        const expDataElement = document.getElementById('experience-data');
        const expContainer = document.getElementById('experience-list-container');
        
        // --- 1. 渲染实习经历函数 ---
        function renderExperience() {
            try {
                const data = JSON.parse(expDataElement.textContent);
                
                let expListHtml = '<ul class="experience-list">';

                data.experiences.forEach(exp => {
                    expListHtml += `
                        <li class="experience-item">
                            <div class="exp-logo">
                                <img src="${exp.logoUrl}" alt="${exp.company} Logo">
                            </div>
                            <div class="exp-company">${exp.company}</div>
                            <div class="exp-title">${exp.title}</div>
                            <div class="exp-period">${exp.period}</div>
                        </li>
                    `;
                });

                expListHtml += '</ul>';
                expContainer.innerHTML = expListHtml;

            } catch (error) {
                console.error("Error rendering experiences:", error);
                expContainer.innerHTML = "<p style='color: var(--color-highlight);'>Error loading experiences. Please check the JSON data structure and image paths.</p>";
            }
        }

        // --- 2. 渲染出版物函数 ---
        function renderPublications() {
            try {
                const data = JSON.parse(pubDataElement.textContent);
                let html = '';

                data.categories.forEach(category => {
                    // 渲染分类标题 (使用语义化 H3)
                    html += `<h3 class="pub-category">${category.title}</h3>`;
                    
                    category.pubs.forEach(pub => {
                        // 1. 准备链接 HTML
                        let linksHtml = pub.links.map(link => {
                            const iconClass = link.icon || 'fa-solid fa-link'; 
                            return `
                                <a href="${link.url}" target="_blank">
                                    <i class="fas ${iconClass}"></i> ${link.text}
                                </a>
                            `;
                        }).join('');

                        // 2. 准备徽章 HTML
                        let badgesHtml = '';
                        if (pub.badge_stars || pub.badge_forks) {
                            badgesHtml = '<span class="pub-badges">';
                            if (pub.badge_stars) badgesHtml += `<img src="${pub.badge_stars}" alt="Stars">`;
                            if (pub.badge_forks) badgesHtml += `<img src="${pub.badge_forks}" alt="Forks">`;
                            badgesHtml += '</span>';
                        }
                        
                        // 3. 准备作者 HTML (替换 **粗体** 标记)
                        const authorsHtml = pub.authors.join(', ').replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
                        
                        // 4. 准备图片 Hover 效果
                        const hoverImage = pub.hoverImageUrl ? `<img src="${pub.hoverImageUrl}" class="hover-image" alt="${pub.title} result">` : '';

                        // 5. 渲染单个论文 Article
                        html += `
                            <article class="publication" data-pub-id="${pub.id}">
                                <div class="pub-image">
                                    <img src="${pub.imageUrl}" alt="${pub.title} cover">
                                    ${hoverImage}
                                </div>
                                <div class="pub-content">
                                    <h4 class="pub-title">${pub.title}</h4>
                                    <p class="pub-authors">${authorsHtml}</p>
                                    <p class="pub-venue">${pub.venue} ${badgesHtml}</p>
                                    <div class="pub-links">${linksHtml}</div>
                                </div>
                            </article>
                        `;
                    });
                });

                // 6. 插入到 DOM 中
                pubContainer.innerHTML = html;

            } catch (error) {
                console.error("Error rendering publications:", error);
                pubContainer.innerHTML = "<p style='color: var(--color-highlight);'>Error loading publications. Please check the JSON data structure.</p>";
            }
        }

        // --- 3. 新闻折叠逻辑 ---
        function initNewsToggle() {
            const newsList = document.getElementById('news-list');
            const toggleBtn = document.getElementById('toggle-news-btn');
            
            if (!newsList || !toggleBtn) return;

            const newsItems = newsList.getElementsByTagName('li');
            const defaultVisibleCount = 5; // 默认显示 5 条新闻
            
            // 只有新闻总数大于默认显示数时才启用折叠功能
            if (newsItems.length <= defaultVisibleCount) {
                toggleBtn.style.display = 'none';
                return;
            }

            // 1. 初始化：隐藏超过阈值的新闻项
            for (let i = defaultVisibleCount; i < newsItems.length; i++) {
                newsItems[i].classList.add('hidden-news');
            }

            // 2. 移除按钮的 visibility: hidden，使其可见
            toggleBtn.style.visibility = 'visible';

            // 3. 切换折叠状态的事件监听器
            toggleBtn.addEventListener('click', () => {
                const isExpanded = toggleBtn.getAttribute('aria-expanded') === 'true';

                for (let i = defaultVisibleCount; i < newsItems.length; i++) {
                    // 切换隐藏项的可见性
                    newsItems[i].classList.toggle('hidden-news');
                }

                // 更新按钮状态和文本
                if (isExpanded) {
                    toggleBtn.setAttribute('aria-expanded', 'false');
                    toggleBtn.innerHTML = '<i class="fas fa-chevron-down"></i> expand more';
                } else {
                    toggleBtn.setAttribute('aria-expanded', 'true');
                    toggleBtn.innerHTML = '<i class="fas fa-chevron-up"></i> collapse';
                }
            });
        }
        
        // 确保在页面加载完成后运行所有初始化逻辑
        document.addEventListener('DOMContentLoaded', () => {
            renderExperience(); 
            renderPublications();
            initNewsToggle(); // <--- 新增调用
        });
    </script>
</body>
</html>